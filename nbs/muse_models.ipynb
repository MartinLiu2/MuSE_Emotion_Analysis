{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "close-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sampler\n",
    "import datasets\n",
    "from earlystopping import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from torch.autograd  import  Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-intellectual",
   "metadata": {},
   "source": [
    "# Acoustic Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-banner",
   "metadata": {},
   "source": [
    "Inputs for acoustic branch will be N x 40 where N [1,33]  \n",
    "Time step: (2, 10) (seconds?)  \n",
    "N: relative duration after feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elect-brunswick",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "class AcousticNet(nn.Module):\n",
    "    def __init__(self, num_conv_layers = 3, kernel_size = 2, conv_width = 32, num_gru_layers = 2):\n",
    "        super(AcousticNet, self).__init__()\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=40, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=conv_width, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=conv_width, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=conv_width, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.convs = [self.conv1, self.conv2, self.conv3, self.conv4]\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size = 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=conv_width,hidden_size=32,num_layers=num_gru_layers) # 19 is hardcoded\n",
    "        self.mean_pool = nn.AvgPool1d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1, 2) \n",
    "#         print(x.shape)\n",
    "        for i in range(self.num_conv_layers):\n",
    "            x = self.relu(self.max_pool(self.convs[i](x)))\n",
    "        x = torch.transpose(x, 1, 2) \n",
    "        x, _ = self.gru(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = F.adaptive_avg_pool1d(x,1)[:, :, -1]\n",
    "#         x = self.mean_pool(x)\n",
    "        return x\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ultimate-header",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of output: torch.Size([8, 32])\n"
     ]
    }
   ],
   "source": [
    "# Test dummy input\n",
    "net = AcousticNet(num_conv_layers = 3, kernel_size = 2, conv_width = 32, num_gru_layers = 2)\n",
    "batch_size = 8\n",
    "n_acoustic_channels = 40\n",
    "duration_acoustic = 1232\n",
    "test_vec = torch.randn(batch_size, duration_acoustic, n_acoustic_channels) # samples x features (or channels) x N (relative duration)\n",
    "output = net(test_vec)\n",
    "print(f'Shape of output: {output.shape}')\n",
    "# assert output.shape[-1] == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-graham",
   "metadata": {},
   "source": [
    "# Lexical Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vanilla-juvenile",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# implement GRU (or transformer)\n",
    "class LexicalNet(nn.Module):\n",
    "    def __init__(self, num_gru_layers = 2):\n",
    "        super(LexicalNet, self).__init__()\n",
    "        # implement GRU (or transformer)\n",
    "        self.gru = nn.GRU(input_size=768,hidden_size=32,num_layers=num_gru_layers)\n",
    "        self.mean_pool = nn.AvgPool1d(kernel_size=2) \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "#         x = self.mean_pool(x)\n",
    "        x = self.flatten(x)\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artistic-exposure",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Test dummy input\n",
    "net = LexicalNet(num_gru_layers = 2)\n",
    "batch_size = 8\n",
    "test_vec = torch.randn(batch_size, 1, 768)\n",
    "output = net(test_vec)\n",
    "# assert output.shape[-1] == 16\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-commander",
   "metadata": {},
   "source": [
    "# Master branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tribal-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRL(Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self,x):\n",
    "#         return x\n",
    "#     @staticmethod\n",
    "#     def backward(self,grad_output):\n",
    "#         grad_input = grad_output.neg()\n",
    "#         return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "analyzed-county",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "class GradientReversalFunction(Function):\n",
    "    \"\"\"\n",
    "    Gradient Reversal Layer from:\n",
    "    Unsupervised Domain Adaptation by Backpropagation (Ganin & Lempitsky, 2015)\n",
    "    Forward pass is the identity function. In the backward pass,\n",
    "    the upstream gradients are multiplied by -lambda (i.e. gradient is reversed)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grads):\n",
    "        lambda_ = ctx.lambda_\n",
    "        lambda_ = grads.new_tensor(lambda_)\n",
    "        dx = -lambda_ * grads\n",
    "        return dx, None\n",
    "    \n",
    "class GradientReversal(torch.nn.Module):\n",
    "    def __init__(self, lambda_=1):\n",
    "        super(GradientReversal, self).__init__()\n",
    "        self.lambda_ = lambda_\n",
    "        print(self.lambda_)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.lambda_)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "immediate-trout",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "class MasterNet(nn.Module):\n",
    "    def __init__(self, acoustic_modality = True, lexical_modality = True, visual_modality = False,\n",
    "                 num_conv_layers = 3, kernel_size = 2, conv_width = 32, num_gru_layers = 2,\n",
    "                 num_dense_layers = 1, dense_layer_width = 32, grl_lambda = .3):\n",
    "        super(MasterNet, self).__init__()\n",
    "        \n",
    "        self.acoustic_modality = acoustic_modality\n",
    "        self.lexical_modality = lexical_modality\n",
    "        self.visual_modality = visual_modality\n",
    "        \n",
    "        self.acoustic_model = AcousticNet(num_conv_layers = num_conv_layers, kernel_size = kernel_size, \n",
    "                                     conv_width = conv_width, num_gru_layers = num_gru_layers)\n",
    "        self.lexical_model = LexicalNet(num_gru_layers = 2)\n",
    "        \n",
    "        # emotion classifier\n",
    "#         self.dense1_emo = nn.Linear()\n",
    "#         self.dense2_emo = nn.Linear()\n",
    "        \n",
    "        width = 0 # width of the FC layers\n",
    "        if self.acoustic_modality:\n",
    "            width += 32\n",
    "        if self.visual_modality:\n",
    "            width += 0 # to implement\n",
    "        if self.lexical_modality:\n",
    "            width += 32\n",
    "            \n",
    "        self.fc_1 = nn.Linear(width, dense_layer_width)\n",
    "        self.fc_2 = nn.Linear(dense_layer_width, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "#         # To implement   \n",
    "#         if num_dense_layers == 2:\n",
    "#             self.fc = nn.Sequential()\n",
    "#             self.linear_1 = nn.Linear(width, dense_layer_width)\n",
    "#         else:\n",
    "#             self.fc = \n",
    "        \n",
    "        # confound classifier -- to implement\n",
    "        self.grl = GradientReversal(lambda_ = grl_lambda)\n",
    "        self.dense_conv = nn.Linear(width, 2)\n",
    "#         self.dense2_con = None\n",
    "        \n",
    "        \n",
    "    def forward_a(self, x_a):\n",
    "        x = x_a\n",
    "        x = self.acoustic_model(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_l(self, x_l):\n",
    "        x = torch.unsqueeze(x_l, dim = 1)\n",
    "        x = self.lexical_model(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_v(self, x_v):\n",
    "        x = x_v\n",
    "        return x\n",
    "    \n",
    "    def encoder(self, x_v, x_a, x_l):\n",
    "        if self.visual_modality:\n",
    "            x_v = self.forward_v(x_v)\n",
    "        if self.acoustic_modality:\n",
    "            x_a = self.forward_a(x_a)\n",
    "        if self.lexical_modality:\n",
    "            x_l = self.forward_l(x_l)\n",
    "        \n",
    "        if self.visual_modality:\n",
    "            if self.acoustic_modality:\n",
    "                if self.lexical_modality:\n",
    "                    x = torch.cat((x_v, x_a, x_l), 1)\n",
    "                else:\n",
    "                    x = torch.cat((x_v, x_a), 1)\n",
    "            else:\n",
    "                if self.lexical_modality:\n",
    "                    x = torch.cat((x_v, x_l), 1)\n",
    "                else:\n",
    "                    x = x_v\n",
    "        else:\n",
    "            if self.acoustic_modality:\n",
    "                if self.lexical_modality:\n",
    "                    x = torch.cat((x_a, x_l), 1)\n",
    "                else:\n",
    "                    x = x_a\n",
    "            else:\n",
    "                x = x_l\n",
    "        return x\n",
    "\n",
    "    def confound_model(self, x):\n",
    "#         x = self.grl.apply(x)\n",
    "        x = self.grl(x)\n",
    "        x = self.dense_conv(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    # For emotion\n",
    "    def recognizer(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x_v, x_a, x_l):\n",
    "        x = self.encoder(x_v, x_a, x_l)\n",
    "        emotion_output = self.recognizer(x)\n",
    "        confound_output = self.confound_model(x)\n",
    "        \n",
    "        return emotion_output, confound_output\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wired-cherry",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3\nShape of emotion output: torch.Size([8, 3])\nShape of stress output: torch.Size([8, 2])\ntensor([[0.3734, 0.3499, 0.2767],\n        [0.3834, 0.3470, 0.2696],\n        [0.3817, 0.3582, 0.2601],\n        [0.3846, 0.3558, 0.2597],\n        [0.3780, 0.3447, 0.2772],\n        [0.3935, 0.3294, 0.2771],\n        [0.3893, 0.3298, 0.2809],\n        [0.3767, 0.3359, 0.2875]], grad_fn=<SoftmaxBackward>)\ntensor([[0.5450, 0.4550],\n        [0.5328, 0.4672],\n        [0.5328, 0.4672],\n        [0.5253, 0.4747],\n        [0.5152, 0.4848],\n        [0.5285, 0.4715],\n        [0.5485, 0.4515],\n        [0.5285, 0.4715]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test dummy input\n",
    "net = MasterNet()\n",
    "batch_size = 8\n",
    "n_acoustic_channels = 40\n",
    "duration_acoustic = 1232\n",
    "acoustic_features = torch.randn(batch_size, duration_acoustic, n_acoustic_channels) # samples x features (or channels) x N (relative duration)\n",
    "# lexical_features = torch.randn(batch_size, 1, 300)\n",
    "lexical_features = torch.randn(batch_size, 768)\n",
    "visual_features = None\n",
    "emotion_output, stress_output = net(visual_features, acoustic_features, lexical_features)\n",
    "print(f'Shape of emotion output: {emotion_output.shape}')\n",
    "print(f'Shape of stress output: {stress_output.shape}')\n",
    "print(emotion_output)\n",
    "print(stress_output)\n",
    "# assert output.shape[-1] == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "radical-promise",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Use specific GPU\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():  \n",
    "        dev = \"cuda:0\" \n",
    "    else:  \n",
    "        dev = \"cpu\"  \n",
    "    return torch.device(dev)\n",
    "device = get_device()\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lightweight-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_folder(model, folder = 0, epochs = 1, verbose = False, learning_rate = 1e-4, patience = 5):\n",
    "    # Use specific GPU\n",
    "    device = get_device()\n",
    "\n",
    "    # Dataloaders    \n",
    "    train_dataset_file_path = '../dataset/IEMOCAP/' + str(folder) + '/train.csv'\n",
    "    train_loader = datasets.get_dataloader(train_dataset_file_path, 'train')\n",
    "    test_dataset_file_path = '../dataset/IEMOCAP/' + str(folder) + '/test.csv'\n",
    "    test_loader = datasets.get_dataloader(test_dataset_file_path, 'test')\n",
    "\n",
    "    # Model, optimizer and loss function\n",
    "    init_weights(model)\n",
    "    for param in emotion_recognizer.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc = 0.\n",
    "    best_uar = 0.\n",
    "    es = EarlyStopping(patience=patience)\n",
    "\n",
    "    # Train and validate\n",
    "    for epoch in range(epochs):\n",
    "        if verbose:\n",
    "            print('epoch: {}/{}'.format(epoch + 1, epochs))\n",
    "\n",
    "        train_loss, train_acc = train(train_loader, model,\n",
    "                                        optimizer, criterion, device)\n",
    "        test_loss, test_acc, test_uar = test(test_loader, model,\n",
    "                                                criterion, device)\n",
    "\n",
    "        if verbose:\n",
    "            print('train_emotion_loss: {0:.5f}'.format(train_loss['emotion_loss']),\n",
    "                  'train_emotion_acc: {0:.3f}'.format(train_acc['emotion_acc']),\n",
    "                  'train_confound_loss: {0:.5f}'.format(train_loss['confound_loss']),\n",
    "                  'train_confound_acc: {0:.3f}'.format(train_acc['confound_acc']),\n",
    "                  'test_emotion_loss: {0:.5f}'.format(test_loss['emotion_loss']),\n",
    "                  'test_emotion_acc: {0:.3f}'.format(test_acc['emotion_acc']),\n",
    "                  'test_confound_loss: {0:.5f}'.format(test_loss['confound_loss']),\n",
    "                  'test_confound_acc: {0:.3f}'.format(test_acc['confound_acc']),\n",
    "                  'test_emotion_uar: {0:.3f}'.format(test_uar['emotion_uar']),\n",
    "                  'test_confound_uar: {0:.3f}'.format(test_uar['confound_uar']))\n",
    "\n",
    "        lr_schedule.step(test_loss['loss'])\n",
    "\n",
    "#         os.makedirs(os.path.join(opt.logger_path, opt.source_domain), exist_ok=True)\n",
    "\n",
    "#         model_file_name = os.path.join(opt.logger_path, opt.source_domain, 'checkpoint.pth.tar')\n",
    "#         state = {'epoch': epoch+1, 'emotion_recognizer': emotion_recognizer.state_dict(), 'opt': opt}\n",
    "#         torch.save(state, model_file_name)\n",
    "\n",
    "        if test_acc['emotion_acc'] > best_acc:\n",
    "#             model_file_name = os.path.join(opt.logger_path, opt.source_domain, 'model.pth.tar')\n",
    "#             torch.save(state, model_file_name)\n",
    "\n",
    "            best_acc = test_acc['emotion_acc']\n",
    "\n",
    "        if test_uar['emotion_uar'] > best_uar:\n",
    "            best_uar = test_uar['emotion_uar']\n",
    "\n",
    "        if es.step(test_loss['emotion_loss']):\n",
    "            break\n",
    "\n",
    "    return best_acc, best_uar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "other-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_baseline(train_loader, model, optimizer, criterion, device, verbose = False):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    groundtruth = []\n",
    "    prediction = []\n",
    "\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        visual_features, _, acoustic_features, _, lexical_features, _, _, a_labels, _, _ = train_data # UPDATE\n",
    "\n",
    "        visual_features = visual_features.to(device)\n",
    "        acoustic_features = acoustic_features.to(device)\n",
    "        lexical_features = lexical_features.to(device)\n",
    "\n",
    "        labels = a_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emotion_output, stress_output = model(visual_features, acoustic_features, lexical_features)\n",
    "\n",
    "        emotion_loss = criterion(emotion_output, labels)\n",
    "#         stress_loss = criterion(stress_output, stress_labels)\n",
    "\n",
    "        emotion_loss.backward()\n",
    "#         stress_loss.backward()\n",
    "        \n",
    "        optimizer.step() # do we need two optimizers?\n",
    "        \n",
    "        running_loss += emotion_loss.item()\n",
    "\n",
    "        groundtruth.append(labels.tolist())\n",
    "        predictions = emotion_output.argmax(dim=1, keepdim=True)\n",
    "        prediction.append(predictions.view_as(labels).tolist())\n",
    "\n",
    "        if verbose and i > 0 and int(len(train_loader) / 10) > 0 and i % (int(len(train_loader) / 10)) == 0:\n",
    "            print('.', flush=True, end='')\n",
    "            \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    groundtruth = list(itertools.chain.from_iterable(groundtruth))\n",
    "    prediction = list(itertools.chain.from_iterable(prediction))\n",
    "\n",
    "    train_acc = accuracy_score(prediction, groundtruth)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "silent-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, device, verbose = False):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    emotion_running_loss = 0.\n",
    "    confound_running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    emotion_groundtruth = []\n",
    "    emotion_prediction = []\n",
    "    \n",
    "    confound_groundtruth = []\n",
    "    confound_prediction = []\n",
    "\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        visual_features, _, acoustic_features, _, lexical_features, _, _, a_labels, d_labels, s_labels, _ = train_data # UPDATE\n",
    "\n",
    "        visual_features = visual_features.to(device)\n",
    "        acoustic_features = acoustic_features.to(device)\n",
    "        lexical_features = lexical_features.to(device)\n",
    "\n",
    "        emotion_labels = a_labels.to(device)\n",
    "        confound_labels = s_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emotion_predictions, confound_predictions = model(visual_features, acoustic_features, lexical_features)\n",
    "\n",
    "        emotion_loss = criterion(emotion_predictions, emotion_labels)\n",
    "        confound_loss = criterion(confound_predictions, confound_labels)\n",
    "        loss = emotion_loss + confound_loss\n",
    "        \n",
    "        loss.backward()\n",
    "#         emotion_loss.backward()\n",
    "#         confound_loss.backward()\n",
    "        \n",
    "        optimizer.step() # do we need two optimizers?\n",
    "        \n",
    "        emotion_running_loss += emotion_loss.item()\n",
    "        confound_running_loss += confound_loss.item()\n",
    "        running_loss += emotion_running_loss + confound_running_loss\n",
    "\n",
    "        emotion_groundtruth.append(emotion_labels.tolist())\n",
    "        emotion_predictions = emotion_predictions.argmax(dim=1, keepdim=True)\n",
    "        emotion_prediction.append(emotion_predictions.view_as(emotion_labels).tolist())\n",
    "        \n",
    "        confound_groundtruth.append(confound_labels.tolist())\n",
    "        confound_predictions = confound_predictions.argmax(dim=1, keepdim=True)\n",
    "        confound_prediction.append(confound_predictions.view_as(confound_labels).tolist())\n",
    "\n",
    "        if verbose and i > 0 and int(len(train_loader) / 10) > 0 and i % (int(len(train_loader) / 10)) == 0:\n",
    "            print('.', flush=True, end='')\n",
    "        \n",
    "    emotion_loss = emotion_running_loss / len(train_loader)\n",
    "    confound_loss = confound_running_loss / len(train_loader)\n",
    "    loss = running_loss / len(train_loader)\n",
    "    train_loss = {'emotion_loss': emotion_loss,\n",
    "                  'confound_loss': confound_loss,\n",
    "                  'loss': loss\n",
    "                 }\n",
    "\n",
    "    emotion_groundtruth = list(itertools.chain.from_iterable(emotion_groundtruth))\n",
    "    emotion_prediction = list(itertools.chain.from_iterable(emotion_prediction))\n",
    "    \n",
    "    confound_groundtruth = list(itertools.chain.from_iterable(confound_groundtruth))\n",
    "    confound_prediction = list(itertools.chain.from_iterable(confound_prediction))\n",
    "\n",
    "    emotion_acc = accuracy_score(emotion_prediction, emotion_groundtruth)\n",
    "    confound_acc = accuracy_score(confound_prediction, confound_groundtruth)\n",
    "    avg_acc = (emotion_acc + confound_acc) / 2\n",
    "    \n",
    "    train_acc = {'emotion_acc': emotion_acc,\n",
    "                  'confound_acc': confound_acc\n",
    "                }\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "intended-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        groundtruth = []\n",
    "        prediction = []\n",
    "\n",
    "        for i, test_data in enumerate(test_loader):\n",
    "            visual_features, _, acoustic_features, _, lexical_features, _, v_labels, a_labels, d_labels, _ = test_data # UPDATE\n",
    "\n",
    "            visual_features = visual_features.to(device)\n",
    "            acoustic_features = acoustic_features.to(device)\n",
    "            lexical_features = lexical_features.to(device)\n",
    "\n",
    "            labels = a_labels.to(device)\n",
    "\n",
    "            emotion_predictions, confound_predictions = model(visual_features, acoustic_features, lexical_features)\n",
    "            loss = criterion(emotion_predictions, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            groundtruth.append(labels.tolist())\n",
    "            emotion_predictions = emotion_predictions.argmax(dim=1, keepdim=True)\n",
    "            prediction.append(emotion_predictions.view_as(labels).tolist())\n",
    "\n",
    "        test_loss = running_loss / len(test_loader)\n",
    "\n",
    "        groundtruth = list(itertools.chain.from_iterable(groundtruth))\n",
    "        prediction = list(itertools.chain.from_iterable(prediction))\n",
    "\n",
    "        test_acc = accuracy_score(prediction, groundtruth)\n",
    "        test_uar = recall_score(prediction, groundtruth, average='macro')\n",
    "\n",
    "        return test_loss, test_acc, test_uar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "olive-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.\n",
    "    emotion_running_loss = 0.\n",
    "    confound_running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emotion_groundtruth = []\n",
    "        emotion_prediction = []\n",
    "\n",
    "        confound_groundtruth = []\n",
    "        confound_prediction = []\n",
    "\n",
    "        for i, test_data in enumerate(test_loader):\n",
    "            visual_features, _, acoustic_features, _, lexical_features, _, v_labels, a_labels, d_labels, s_labels, _ = test_data # UPDATE\n",
    "\n",
    "            visual_features = visual_features.to(device)\n",
    "            acoustic_features = acoustic_features.to(device)\n",
    "            lexical_features = lexical_features.to(device)\n",
    "\n",
    "            emotion_labels = a_labels.to(device)\n",
    "            confound_labels = s_labels.to(device)\n",
    "\n",
    "            emotion_predictions, confound_predictions = model(visual_features, acoustic_features, lexical_features)\n",
    "            \n",
    "            emotion_loss = criterion(emotion_predictions, emotion_labels)\n",
    "            confound_loss = criterion(confound_predictions, confound_labels)\n",
    "            loss = emotion_loss + confound_loss\n",
    "\n",
    "            emotion_running_loss += emotion_loss.item()\n",
    "            confound_running_loss += confound_loss.item()\n",
    "            running_loss += emotion_running_loss + confound_running_loss\n",
    "\n",
    "            emotion_groundtruth.append(emotion_labels.tolist())\n",
    "            emotion_predictions = emotion_predictions.argmax(dim=1, keepdim=True)\n",
    "            emotion_prediction.append(emotion_predictions.view_as(emotion_labels).tolist())\n",
    "\n",
    "            confound_groundtruth.append(confound_labels.tolist())\n",
    "            confound_predictions = confound_predictions.argmax(dim=1, keepdim=True)\n",
    "            confound_prediction.append(confound_predictions.view_as(confound_labels).tolist())\n",
    "\n",
    "        emotion_loss = emotion_running_loss / len(train_loader)\n",
    "        confound_loss = confound_running_loss / len(train_loader)\n",
    "        loss = running_loss / len(train_loader)\n",
    "        test_loss = {'emotion_loss': emotion_loss,\n",
    "                     'confound_loss': confound_loss,\n",
    "                     'loss': loss\n",
    "                    }\n",
    "\n",
    "        emotion_groundtruth = list(itertools.chain.from_iterable(emotion_groundtruth))\n",
    "        emotion_prediction = list(itertools.chain.from_iterable(emotion_prediction))\n",
    "\n",
    "        confound_groundtruth = list(itertools.chain.from_iterable(confound_groundtruth))\n",
    "        confound_prediction = list(itertools.chain.from_iterable(confound_prediction))\n",
    "\n",
    "        emotion_acc = accuracy_score(emotion_prediction, emotion_groundtruth)\n",
    "        confound_acc = accuracy_score(confound_prediction, confound_groundtruth)\n",
    "        avg_acc = (emotion_acc + confound_acc) / 2\n",
    "        test_acc = {'emotion_acc': emotion_acc,\n",
    "                    'confound_acc': confound_acc\n",
    "                   }\n",
    "        \n",
    "        emotion_uar = recall_score(emotion_prediction, emotion_groundtruth, average='macro')\n",
    "        confound_uar = recall_score(confound_prediction, confound_groundtruth, average='macro')\n",
    "\n",
    "        test_uar = {'emotion_uar': emotion_uar,\n",
    "                    'confound_uar': confound_uar\n",
    "                   }\n",
    "\n",
    "        return test_loss, test_acc, test_uar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hungarian-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "thirty-mount",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n",
      "Train loss: {'emotion_loss': 1.0981351366766696, 'confound_loss': 0.7066611929394392, 'loss': 926.845338945201}\n",
      "Train acc: {'emotion_acc': 0.3389294403892944, 'confound_acc': 0.42871046228710463}\n",
      "Train loss: {'emotion_loss': 1.0977485787543806, 'confound_loss': 0.7066572762532921, 'loss': 929.6342194606242}\n",
      "Train acc: {'emotion_acc': 0.35559610705596106, 'confound_acc': 0.47883211678832116}\n",
      "Train loss: {'emotion_loss': 1.0957260444934267, 'confound_loss': 0.6897924189321726, 'loss': 918.6401573025299}\n",
      "Train acc: {'emotion_acc': 0.38467153284671535, 'confound_acc': 0.5220194647201947}\n",
      "Train loss: {'emotion_loss': 1.092714290210709, 'confound_loss': 0.6951026301323672, 'loss': 920.2137848959243}\n",
      "Train acc: {'emotion_acc': 0.3878345498783455, 'confound_acc': 0.46982968369829686}\n",
      "Train loss: {'emotion_loss': 1.0887240962875493, 'confound_loss': 0.6946145202747115, 'loss': 918.3460953248382}\n",
      "Train acc: {'emotion_acc': 0.4054744525547445, 'confound_acc': 0.46727493917274937}\n",
      "Train loss: {'emotion_loss': 1.0848299234177816, 'confound_loss': 0.6927917233816845, 'loss': 915.5851444792771}\n",
      "Train acc: {'emotion_acc': 0.3998783454987834, 'confound_acc': 0.5100973236009733}\n",
      "Train loss: {'emotion_loss': 1.0724755622997357, 'confound_loss': 0.6946552519900325, 'loss': 909.6110539022934}\n",
      "Train acc: {'emotion_acc': 0.4278588807785888, 'confound_acc': 0.4708029197080292}\n",
      "Train loss: {'emotion_loss': 1.0594178330341666, 'confound_loss': 0.6929099476870859, 'loss': 903.4402361503487}\n",
      "Train acc: {'emotion_acc': 0.4468369829683698, 'confound_acc': 0.5059610705596107}\n",
      "Train loss: {'emotion_loss': 1.0409024185591635, 'confound_loss': 0.6930069234584556, 'loss': 893.4444185472764}\n",
      "Train acc: {'emotion_acc': 0.47214111922141117, 'confound_acc': 0.5109489051094891}\n",
      "Train loss: {'emotion_loss': 1.0320531165785363, 'confound_loss': 0.6930824578504154, 'loss': 888.3718328296211}\n",
      "Train acc: {'emotion_acc': 0.47956204379562045, 'confound_acc': 0.5030413625304136}\n",
      "Train loss: {'emotion_loss': 1.015348934419888, 'confound_loss': 0.694569025464095, 'loss': 880.4424489787581}\n",
      "Train acc: {'emotion_acc': 0.5038929440389295, 'confound_acc': 0.4701946472019465}\n",
      "Train loss: {'emotion_loss': 1.006977194536057, 'confound_loss': 0.6937409725750466, 'loss': 877.4242645423236}\n",
      "Train acc: {'emotion_acc': 0.5090024330900244, 'confound_acc': 0.5054744525547445}\n",
      "Train loss: {'emotion_loss': 1.0035641885105273, 'confound_loss': 0.6917556884919623, 'loss': 873.1234023412726}\n",
      "Train acc: {'emotion_acc': 0.5215328467153285, 'confound_acc': 0.51338199513382}\n",
      "Train loss: {'emotion_loss': 0.9860193160025527, 'confound_loss': 0.6945797064656878, 'loss': 866.7394884105786}\n",
      "Train acc: {'emotion_acc': 0.5395377128953771, 'confound_acc': 0.4673965936739659}\n",
      "Train loss: {'emotion_loss': 0.9901459675702603, 'confound_loss': 0.6945346567185472, 'loss': 867.2634517931984}\n",
      "Train acc: {'emotion_acc': 0.5386861313868613, 'confound_acc': 0.4510948905109489}\n",
      "Train loss: {'emotion_loss': 0.9718034639084849, 'confound_loss': 0.6928566393337361, 'loss': 859.8213345850836}\n",
      "Train acc: {'emotion_acc': 0.5643552311435523, 'confound_acc': 0.5156934306569343}\n",
      "Train loss: {'emotion_loss': 0.9615584571885691, 'confound_loss': 0.6940289974096684, 'loss': 849.5214402400798}\n",
      "Train acc: {'emotion_acc': 0.5762773722627738, 'confound_acc': 0.5009732360097323}\n",
      "Train loss: {'emotion_loss': 0.949930442214476, 'confound_loss': 0.6933110381262776, 'loss': 844.2643865831632}\n",
      "Train acc: {'emotion_acc': 0.5920924574209245, 'confound_acc': 0.5064476885644769}\n",
      "Train loss: {'emotion_loss': 0.9377744361352364, 'confound_loss': 0.694352114246977, 'loss': 840.7245463646572}\n",
      "Train acc: {'emotion_acc': 0.6109489051094891, 'confound_acc': 0.47798053527980533}\n",
      "Train loss: {'emotion_loss': 0.9283939012641573, 'confound_loss': 0.6923661140964189, 'loss': 834.7362655674322}\n",
      "Train acc: {'emotion_acc': 0.6085158150851582, 'confound_acc': 0.5130170316301703}\n",
      "Train loss: {'emotion_loss': 0.9177773216819021, 'confound_loss': 0.6934790331797841, 'loss': 829.6982186999651}\n",
      "Train acc: {'emotion_acc': 0.6307785888077859, 'confound_acc': 0.5038929440389295}\n",
      "Train loss: {'emotion_loss': 0.915435565120979, 'confound_loss': 0.6931374644143108, 'loss': 828.8494228193036}\n",
      "Train acc: {'emotion_acc': 0.628102189781022, 'confound_acc': 0.5006082725060828}\n",
      "Train loss: {'emotion_loss': 0.9092898147347372, 'confound_loss': 0.6934926108627468, 'loss': 825.2406552400339}\n",
      "Train acc: {'emotion_acc': 0.6375912408759125, 'confound_acc': 0.5}\n",
      "Train loss: {'emotion_loss': 0.8960367205193999, 'confound_loss': 0.6925684180009226, 'loss': 817.8207904437869}\n",
      "Train acc: {'emotion_acc': 0.6532846715328468, 'confound_acc': 0.5153284671532846}\n",
      "Train loss: {'emotion_loss': 0.8896680946827863, 'confound_loss': 0.6934120057853743, 'loss': 815.465270083992}\n",
      "Train acc: {'emotion_acc': 0.6586374695863747, 'confound_acc': 0.5052311435523115}\n",
      "Train loss: {'emotion_loss': 0.8870705283801379, 'confound_loss': 0.6928346190703054, 'loss': 813.2011034169782}\n",
      "Train acc: {'emotion_acc': 0.6604622871046228, 'confound_acc': 0.5136253041362531}\n",
      "Train loss: {'emotion_loss': 0.8780996921809266, 'confound_loss': 0.693108319540432, 'loss': 810.1349851647935}\n",
      "Train acc: {'emotion_acc': 0.6699513381995134, 'confound_acc': 0.505352798053528}\n",
      "Train loss: {'emotion_loss': 0.8764326033773125, 'confound_loss': 0.6933046242490353, 'loss': 810.083936051288}\n",
      "Train acc: {'emotion_acc': 0.6711678832116789, 'confound_acc': 0.5057177615571776}\n",
      "Train loss: {'emotion_loss': 0.8675790655821678, 'confound_loss': 0.6930124192038398, 'loss': 803.3235135175838}\n",
      "Train acc: {'emotion_acc': 0.67992700729927, 'confound_acc': 0.5062043795620438}\n",
      "Train loss: {'emotion_loss': 0.8658101806844719, 'confound_loss': 0.693652800142997, 'loss': 803.9931656808125}\n",
      "Train acc: {'emotion_acc': 0.6849148418491484, 'confound_acc': 0.5018248175182481}\n",
      "Train loss: {'emotion_loss': 0.8570626474887945, 'confound_loss': 0.6931379214798894, 'loss': 799.4913488259459}\n",
      "Train acc: {'emotion_acc': 0.690632603406326, 'confound_acc': 0.5010948905109489}\n",
      "Train loss: {'emotion_loss': 0.8454156447245453, 'confound_loss': 0.6939490193986707, 'loss': 792.6000278425124}\n",
      "Train acc: {'emotion_acc': 0.7034063260340633, 'confound_acc': 0.4829683698296837}\n",
      "Train loss: {'emotion_loss': 0.8525235296339376, 'confound_loss': 0.6935568840935072, 'loss': 794.4217229958058}\n",
      "Train acc: {'emotion_acc': 0.6968369829683698, 'confound_acc': 0.491970802919708}\n",
      "Train loss: {'emotion_loss': 0.8396709806028507, 'confound_loss': 0.6930393485591569, 'loss': 785.9927897269508}\n",
      "Train acc: {'emotion_acc': 0.7115571776155718, 'confound_acc': 0.5060827250608273}\n",
      "Train loss: {'emotion_loss': 0.8402902079231545, 'confound_loss': 0.6939938670234458, 'loss': 789.7490955477558}\n",
      "Train acc: {'emotion_acc': 0.710948905109489, 'confound_acc': 0.47980535279805353}\n",
      "Train loss: {'emotion_loss': 0.8423057888500421, 'confound_loss': 0.6934085043603808, 'loss': 792.3996682448262}\n",
      "Train acc: {'emotion_acc': 0.7063260340632603, 'confound_acc': 0.5034063260340632}\n",
      "Train loss: {'emotion_loss': 0.8320911483773925, 'confound_loss': 0.6933991538527411, 'loss': 785.2638824800689}\n",
      "Train acc: {'emotion_acc': 0.7152068126520681, 'confound_acc': 0.4978102189781022}\n",
      "Train loss: {'emotion_loss': 0.828996299827609, 'confound_loss': 0.6930514874393374, 'loss': 781.2351816573148}\n",
      "Train acc: {'emotion_acc': 0.7210462287104623, 'confound_acc': 0.5099756690997567}\n",
      "Train loss: {'emotion_loss': 0.8191886755858878, 'confound_loss': 0.6934544344936363, 'loss': 778.7377300226503}\n",
      "Train acc: {'emotion_acc': 0.7299270072992701, 'confound_acc': 0.502676399026764}\n",
      "Train loss: {'emotion_loss': 0.8157751993910348, 'confound_loss': 0.6934722466575496, 'loss': 777.5213484400557}\n",
      "Train acc: {'emotion_acc': 0.7349148418491485, 'confound_acc': 0.48503649635036494}\n",
      "Train loss: {'emotion_loss': 0.8187419541383067, 'confound_loss': 0.6932676576570778, 'loss': 778.9552042089432}\n",
      "Train acc: {'emotion_acc': 0.7306569343065693, 'confound_acc': 0.5110705596107056}\n",
      "Train loss: {'emotion_loss': 0.8053276991102019, 'confound_loss': 0.6934648773665558, 'loss': 771.8186704224765}\n",
      "Train acc: {'emotion_acc': 0.745742092457421, 'confound_acc': 0.4979318734793187}\n",
      "Train loss: {'emotion_loss': 0.8167754654058687, 'confound_loss': 0.6932160500654451, 'loss': 777.6950631156737}\n",
      "Train acc: {'emotion_acc': 0.7330900243309002, 'confound_acc': 0.5009732360097323}\n",
      "Train loss: {'emotion_loss': 0.8075369700847432, 'confound_loss': 0.6938214874916967, 'loss': 775.146723080586}\n",
      "Train acc: {'emotion_acc': 0.7414841849148418, 'confound_acc': 0.47907542579075424}\n",
      "Train loss: {'emotion_loss': 0.8072239909654462, 'confound_loss': 0.693409664331707, 'loss': 771.2204923343913}\n",
      "Train acc: {'emotion_acc': 0.7448905109489051, 'confound_acc': 0.49525547445255474}\n",
      "Train loss: {'emotion_loss': 0.7995933221239988, 'confound_loss': 0.6933607421960348, 'loss': 768.1239480126925}\n",
      "Train acc: {'emotion_acc': 0.7507299270072992, 'confound_acc': 0.49659367396593673}\n",
      "Train loss: {'emotion_loss': 0.7891762468833404, 'confound_loss': 0.6934266461472567, 'loss': 759.8498146166945}\n",
      "Train acc: {'emotion_acc': 0.7636253041362531, 'confound_acc': 0.5012165450121655}\n",
      "Train loss: {'emotion_loss': 0.8016629717113443, 'confound_loss': 0.6934191570091804, 'loss': 768.6503184866813}\n",
      "Train acc: {'emotion_acc': 0.7492700729927008, 'confound_acc': 0.49343065693430654}\n",
      "Train loss: {'emotion_loss': 0.784266062515719, 'confound_loss': 0.6936801048684212, 'loss': 761.9620106825569}\n",
      "Train acc: {'emotion_acc': 0.7643552311435523, 'confound_acc': 0.4852798053527981}\n",
      "Train loss: {'emotion_loss': 0.7965504558981624, 'confound_loss': 0.6933078892268095, 'loss': 766.8604382480049}\n",
      "Train acc: {'emotion_acc': 0.7547445255474453, 'confound_acc': 0.505352798053528}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f594c9ce20>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-22T02:08:04.550089</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 378.465625 248.518125 \r\nL 378.465625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m40967c4b1c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m40967c4b1c\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.798835\" xlink:href=\"#m40967c4b1c\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(107.436335 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"175.913862\" xlink:href=\"#m40967c4b1c\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(169.551362 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.02889\" xlink:href=\"#m40967c4b1c\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(231.66639 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"300.143918\" xlink:href=\"#m40967c4b1c\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(293.781418 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"362.258946\" xlink:href=\"#m40967c4b1c\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(355.896446 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mef32cf3183\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"209.815023\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.70 -->\r\n      <g transform=\"translate(7.2 213.614242)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"185.610756\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.75 -->\r\n      <g transform=\"translate(7.2 189.409974)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"161.406488\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.80 -->\r\n      <g transform=\"translate(7.2 165.205707)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"137.202221\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.85 -->\r\n      <g transform=\"translate(7.2 141.001439)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"112.997953\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.90 -->\r\n      <g transform=\"translate(7.2 116.797172)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"88.793686\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.95 -->\r\n      <g transform=\"translate(7.2 92.592905)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"64.589418\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.00 -->\r\n      <g transform=\"translate(7.2 68.388637)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"40.385151\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.05 -->\r\n      <g transform=\"translate(7.2 44.18437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mef32cf3183\" y=\"16.180883\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 1.10 -->\r\n      <g transform=\"translate(7.2 19.980102)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p2ae66d6fd5)\" d=\"M 51.683807 17.083636 \r\nL 57.89531 17.270763 \r\nL 64.106812 18.249843 \r\nL 70.318315 19.707789 \r\nL 76.529818 21.639383 \r\nL 82.741321 23.524495 \r\nL 88.952824 29.50506 \r\nL 95.164326 35.826116 \r\nL 101.375829 44.789157 \r\nL 107.587332 49.072974 \r\nL 113.798835 57.159224 \r\nL 120.010337 61.211861 \r\nL 126.22184 62.864047 \r\nL 132.433343 71.357263 \r\nL 138.644846 69.359611 \r\nL 144.856349 78.238948 \r\nL 151.067851 83.198406 \r\nL 157.279354 88.827358 \r\nL 163.490857 94.711902 \r\nL 169.70236 99.252882 \r\nL 175.913862 104.392212 \r\nL 182.125365 105.525822 \r\nL 188.336868 108.50089 \r\nL 194.548371 114.916519 \r\nL 200.759874 117.999477 \r\nL 206.971376 119.256921 \r\nL 213.182879 123.599571 \r\nL 219.394382 124.406585 \r\nL 225.605885 128.692453 \r\nL 231.817388 129.548744 \r\nL 238.02889 133.783297 \r\nL 244.240393 139.42144 \r\nL 250.451896 135.980617 \r\nL 256.663399 142.202348 \r\nL 262.874901 141.902589 \r\nL 269.086404 140.926876 \r\nL 275.297907 145.871633 \r\nL 281.50941 147.369804 \r\nL 287.720913 152.117531 \r\nL 293.932415 153.769945 \r\nL 300.143918 152.333783 \r\nL 306.355421 158.827427 \r\nL 312.566924 153.285731 \r\nL 318.778426 157.757951 \r\nL 324.989929 157.90946 \r\nL 331.201432 161.603355 \r\nL 337.412935 166.646109 \r\nL 343.624438 160.601468 \r\nL 349.83594 169.023057 \r\nL 356.047443 163.076362 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p2ae66d6fd5)\" d=\"M 51.683807 206.590437 \r\nL 57.89531 206.592333 \r\nL 64.106812 214.756364 \r\nL 70.318315 212.185768 \r\nL 76.529818 212.422055 \r\nL 82.741321 213.304444 \r\nL 88.952824 212.402337 \r\nL 95.164326 213.247214 \r\nL 101.375829 213.200269 \r\nL 107.587332 213.163704 \r\nL 113.798835 212.444078 \r\nL 120.010337 212.844927 \r\nL 126.22184 213.805974 \r\nL 132.433343 212.438908 \r\nL 138.644846 212.460716 \r\nL 144.856349 213.273019 \r\nL 151.067851 212.705498 \r\nL 157.279354 213.053052 \r\nL 163.490857 212.549082 \r\nL 169.70236 213.510476 \r\nL 175.913862 212.971728 \r\nL 182.125365 213.137076 \r\nL 188.336868 212.965155 \r\nL 194.548371 213.412543 \r\nL 200.759874 213.004175 \r\nL 206.971376 213.283679 \r\nL 213.182879 213.151185 \r\nL 219.394382 213.056156 \r\nL 225.605885 213.197609 \r\nL 231.817388 212.88761 \r\nL 238.02889 213.136855 \r\nL 244.240393 212.744214 \r\nL 250.451896 212.934041 \r\nL 256.663399 213.184573 \r\nL 262.874901 212.722504 \r\nL 269.086404 213.00587 \r\nL 275.297907 213.010396 \r\nL 281.50941 213.178696 \r\nL 287.720913 212.983636 \r\nL 293.932415 212.975013 \r\nL 300.143918 213.074051 \r\nL 306.355421 212.97858 \r\nL 312.566924 213.099034 \r\nL 318.778426 212.805951 \r\nL 324.989929 213.005308 \r\nL 331.201432 213.028991 \r\nL 337.412935 212.997087 \r\nL 343.624438 213.000713 \r\nL 349.83594 212.874392 \r\nL 356.047443 213.054576 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 263.154688 44.55625 \r\nL 364.265625 44.55625 \r\nQ 366.265625 44.55625 366.265625 42.55625 \r\nL 366.265625 14.2 \r\nQ 366.265625 12.2 364.265625 12.2 \r\nL 263.154688 12.2 \r\nQ 261.154688 12.2 261.154688 14.2 \r\nL 261.154688 42.55625 \r\nQ 261.154688 44.55625 263.154688 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 265.154688 20.298437 \r\nL 285.154688 20.298437 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_16\">\r\n     <!-- emotion loss -->\r\n     <g transform=\"translate(293.154688 23.798437)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"158.935547\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"220.117188\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"259.326172\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"287.109375\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"348.291016\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"411.669922\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"443.457031\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"471.240234\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"532.421875\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"584.521484\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_20\">\r\n     <path d=\"M 265.154688 34.976562 \r\nL 285.154688 34.976562 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_21\"/>\r\n    <g id=\"text_17\">\r\n     <!-- confound loss -->\r\n     <g transform=\"translate(293.154688 38.476562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 37.109375 75.984375 \r\nL 37.109375 68.5 \r\nL 28.515625 68.5 \r\nQ 23.6875 68.5 21.796875 66.546875 \r\nQ 19.921875 64.59375 19.921875 59.515625 \r\nL 19.921875 54.6875 \r\nL 34.71875 54.6875 \r\nL 34.71875 47.703125 \r\nL 19.921875 47.703125 \r\nL 19.921875 0 \r\nL 10.890625 0 \r\nL 10.890625 47.703125 \r\nL 2.296875 47.703125 \r\nL 2.296875 54.6875 \r\nL 10.890625 54.6875 \r\nL 10.890625 58.5 \r\nQ 10.890625 67.625 15.140625 71.796875 \r\nQ 19.390625 75.984375 28.609375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-102\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"116.162109\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"179.541016\" xlink:href=\"#DejaVuSans-102\"/>\r\n      <use x=\"214.746094\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"275.927734\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"402.685547\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"466.162109\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"497.949219\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"525.732422\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"586.914062\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"639.013672\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p2ae66d6fd5\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "emotion_recognizer = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False, grl_lambda = 10)\n",
    "init_weights(emotion_recognizer)\n",
    "for param in emotion_recognizer.parameters():\n",
    "    param.requires_grad = True\n",
    "emotion_recognizer.to(device)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(emotion_recognizer.parameters(), lr=learning_rate)\n",
    "lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset_file_path = '../dataset/IEMOCAP/0/train.csv'\n",
    "train_loader = datasets.get_dataloader(train_dataset_file_path, 'train')\n",
    "test_dataset_file_path = '../dataset/IEMOCAP/0/test.csv'\n",
    "test_loader = datasets.get_dataloader(test_dataset_file_path, 'test')\n",
    "\n",
    "emotion_loss = []\n",
    "confound_loss = []\n",
    "loss = []\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(train_loader, emotion_recognizer, optimizer, criterion, device)\n",
    "    emotion_loss.append(train_loss['emotion_loss'])\n",
    "    confound_loss.append(train_loss['confound_loss'])\n",
    "    loss.append(train_loss['loss'])\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Train acc: {train_acc}')\n",
    "\n",
    "# plt.plot(range(epochs), loss, label = 'train loss')\n",
    "plt.plot(range(epochs), emotion_loss, label = 'emotion loss')\n",
    "plt.plot(range(epochs), confound_loss, label = 'confound loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "internal-attempt",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-98882667450c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_uar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotion_recognizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test loss: {test_loss}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test acc: {test_acc}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test uar: {test_uar}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-8c7cba35cd5e>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(test_loader, model, criterion, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mconfound_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mvisual_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macoustic_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlexical_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;31m# UPDATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    877\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_uar = test(test_loader, emotion_recognizer, criterion, device)\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test acc: {test_acc}')\n",
    "print(f'Test uar: {test_uar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "featured-hudson",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3de9285698de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plt.plot(range(epochs), loss, label = 'train loss')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotion_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'emotion loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfound_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'confound loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.plot(range(epochs), loss, label = 'train loss')\n",
    "plt.plot(range(epochs), emotion_loss, label = 'emotion loss')\n",
    "plt.plot(range(epochs), confound_loss, label = 'confound loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "antique-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "uar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "regional-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "epoch: 1/10\n",
      "train_emotion_loss: 1.09418 train_emotion_acc: 0.375 train_confound_loss: 0.70122 train_confound_acc: 0.479 test_emotion_loss: 0.23824 test_emotion_acc: 0.484 test_confound_loss: 0.15995 test_confound_acc: 0.411 test_emotion_uar: 0.444 test_confound_uar: 0.407\n",
      "epoch: 2/10\n",
      "train_emotion_loss: 1.04321 train_emotion_acc: 0.491 train_confound_loss: 0.69855 train_confound_acc: 0.471 test_emotion_loss: 0.21883 test_emotion_acc: 0.612 test_confound_loss: 0.15433 test_confound_acc: 0.474 test_emotion_uar: 0.535 test_confound_uar: 0.495\n",
      "epoch: 3/10\n",
      "train_emotion_loss: 0.99746 train_emotion_acc: 0.527 train_confound_loss: 0.69062 train_confound_acc: 0.533 test_emotion_loss: 0.21356 test_emotion_acc: 0.603 test_confound_loss: 0.15075 test_confound_acc: 0.626 test_emotion_uar: 0.532 test_confound_uar: 0.629\n",
      "epoch: 4/10\n",
      "train_emotion_loss: 0.97856 train_emotion_acc: 0.548 train_confound_loss: 0.68800 train_confound_acc: 0.553 test_emotion_loss: 0.20994 test_emotion_acc: 0.620 test_confound_loss: 0.15058 test_confound_acc: 0.624 test_emotion_uar: 0.557 test_confound_uar: 0.619\n",
      "epoch: 5/10\n",
      "train_emotion_loss: 0.96569 train_emotion_acc: 0.568 train_confound_loss: 0.68768 train_confound_acc: 0.552 test_emotion_loss: 0.20969 test_emotion_acc: 0.601 test_confound_loss: 0.15031 test_confound_acc: 0.618 test_emotion_uar: 0.567 test_confound_uar: 0.612\n",
      "epoch: 6/10\n",
      "train_emotion_loss: 0.95518 train_emotion_acc: 0.580 train_confound_loss: 0.68737 train_confound_acc: 0.555 test_emotion_loss: 0.21088 test_emotion_acc: 0.585 test_confound_loss: 0.15143 test_confound_acc: 0.592 test_emotion_uar: 0.580 test_confound_uar: 0.590\n",
      "epoch: 7/10\n",
      "train_emotion_loss: 0.93980 train_emotion_acc: 0.602 train_confound_loss: 0.68638 train_confound_acc: 0.553 test_emotion_loss: 0.21060 test_emotion_acc: 0.580 test_confound_loss: 0.15113 test_confound_acc: 0.589 test_emotion_uar: 0.580 test_confound_uar: 0.569\n",
      "epoch: 8/10\n",
      "train_emotion_loss: 0.94373 train_emotion_acc: 0.595 train_confound_loss: 0.68874 train_confound_acc: 0.536 test_emotion_loss: 0.21044 test_emotion_acc: 0.581 test_confound_loss: 0.15125 test_confound_acc: 0.584 test_emotion_uar: 0.577 test_confound_uar: 0.567\n",
      "epoch: 9/10\n",
      "train_emotion_loss: 0.93226 train_emotion_acc: 0.608 train_confound_loss: 0.68767 train_confound_acc: 0.537 test_emotion_loss: 0.21015 test_emotion_acc: 0.583 test_confound_loss: 0.15107 test_confound_acc: 0.585 test_emotion_uar: 0.574 test_confound_uar: 0.564\n",
      "epoch: 10/10\n",
      "train_emotion_loss: 0.93222 train_emotion_acc: 0.607 train_confound_loss: 0.68893 train_confound_acc: 0.534 test_emotion_loss: 0.20993 test_emotion_acc: 0.584 test_confound_loss: 0.15100 test_confound_acc: 0.586 test_emotion_uar: 0.573 test_confound_uar: 0.565\n"
     ]
    }
   ],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 0, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "legendary-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "epoch: 1/10\n",
      "train_emotion_loss: 1.09286 train_emotion_acc: 0.366 train_confound_loss: 0.70725 train_confound_acc: 0.488 test_emotion_loss: 0.23269 test_emotion_acc: 0.536 test_confound_loss: 0.16578 test_confound_acc: 0.433 test_emotion_uar: 0.524 test_confound_uar: 0.300\n",
      "epoch: 2/10\n",
      "train_emotion_loss: 1.03608 train_emotion_acc: 0.490 train_confound_loss: 0.70085 train_confound_acc: 0.486 test_emotion_loss: 0.21610 test_emotion_acc: 0.584 test_confound_loss: 0.15146 test_confound_acc: 0.647 test_emotion_uar: 0.515 test_confound_uar: 0.641\n",
      "epoch: 3/10\n",
      "train_emotion_loss: 0.99721 train_emotion_acc: 0.525 train_confound_loss: 0.68720 train_confound_acc: 0.574 test_emotion_loss: 0.21237 test_emotion_acc: 0.585 test_confound_loss: 0.14817 test_confound_acc: 0.677 test_emotion_uar: 0.511 test_confound_uar: 0.741\n",
      "epoch: 4/10\n",
      "train_emotion_loss: 0.98384 train_emotion_acc: 0.543 train_confound_loss: 0.68905 train_confound_acc: 0.542 test_emotion_loss: 0.20931 test_emotion_acc: 0.592 test_confound_loss: 0.15112 test_confound_acc: 0.580 test_emotion_uar: 0.526 test_confound_uar: 0.566\n",
      "epoch: 5/10\n",
      "train_emotion_loss: 0.97043 train_emotion_acc: 0.562 train_confound_loss: 0.69250 train_confound_acc: 0.512 test_emotion_loss: 0.21223 test_emotion_acc: 0.563 test_confound_loss: 0.15247 test_confound_acc: 0.527 test_emotion_uar: 0.523 test_confound_uar: 0.534\n",
      "epoch: 6/10\n",
      "train_emotion_loss: 0.95996 train_emotion_acc: 0.573 train_confound_loss: 0.69115 train_confound_acc: 0.527 test_emotion_loss: 0.20834 test_emotion_acc: 0.589 test_confound_loss: 0.15141 test_confound_acc: 0.566 test_emotion_uar: 0.538 test_confound_uar: 0.577\n",
      "epoch: 7/10\n",
      "train_emotion_loss: 0.95111 train_emotion_acc: 0.587 train_confound_loss: 0.68811 train_confound_acc: 0.539 test_emotion_loss: 0.20823 test_emotion_acc: 0.590 test_confound_loss: 0.14953 test_confound_acc: 0.613 test_emotion_uar: 0.548 test_confound_uar: 0.603\n",
      "epoch: 8/10\n",
      "train_emotion_loss: 0.93502 train_emotion_acc: 0.603 train_confound_loss: 0.68799 train_confound_acc: 0.545 test_emotion_loss: 0.20979 test_emotion_acc: 0.576 test_confound_loss: 0.14964 test_confound_acc: 0.601 test_emotion_uar: 0.556 test_confound_uar: 0.590\n",
      "epoch: 9/10\n",
      "train_emotion_loss: 0.93346 train_emotion_acc: 0.603 train_confound_loss: 0.68769 train_confound_acc: 0.542 test_emotion_loss: 0.21031 test_emotion_acc: 0.565 test_confound_loss: 0.15021 test_confound_acc: 0.586 test_emotion_uar: 0.538 test_confound_uar: 0.572\n",
      "epoch: 10/10\n",
      "train_emotion_loss: 0.91863 train_emotion_acc: 0.630 train_confound_loss: 0.68838 train_confound_acc: 0.540 test_emotion_loss: 0.21040 test_emotion_acc: 0.562 test_confound_loss: 0.15042 test_confound_acc: 0.581 test_emotion_uar: 0.535 test_confound_uar: 0.567\n"
     ]
    }
   ],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 1, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "robust-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "epoch: 1/10\n",
      "train_emotion_loss: 1.09586 train_emotion_acc: 0.367 train_confound_loss: 0.70769 train_confound_acc: 0.411 test_emotion_loss: 0.27894 test_emotion_acc: 0.480 test_confound_loss: 0.19097 test_confound_acc: 0.381 test_emotion_uar: 0.666 test_confound_uar: 0.293\n",
      "epoch: 2/10\n",
      "train_emotion_loss: 1.04326 train_emotion_acc: 0.491 train_confound_loss: 0.70410 train_confound_acc: 0.449 test_emotion_loss: 0.25858 test_emotion_acc: 0.563 test_confound_loss: 0.17748 test_confound_acc: 0.561 test_emotion_uar: 0.389 test_confound_uar: 0.756\n",
      "epoch: 3/10\n",
      "train_emotion_loss: 1.00316 train_emotion_acc: 0.523 train_confound_loss: 0.68362 train_confound_acc: 0.560 test_emotion_loss: 0.25328 test_emotion_acc: 0.574 test_confound_loss: 0.17434 test_confound_acc: 0.601 test_emotion_uar: 0.516 test_confound_uar: 0.724\n",
      "epoch: 4/10\n",
      "train_emotion_loss: 0.99133 train_emotion_acc: 0.534 train_confound_loss: 0.68311 train_confound_acc: 0.572 test_emotion_loss: 0.25110 test_emotion_acc: 0.576 test_confound_loss: 0.17599 test_confound_acc: 0.571 test_emotion_uar: 0.538 test_confound_uar: 0.645\n",
      "epoch: 5/10\n",
      "train_emotion_loss: 0.96493 train_emotion_acc: 0.569 train_confound_loss: 0.68576 train_confound_acc: 0.555 test_emotion_loss: 0.25047 test_emotion_acc: 0.559 test_confound_loss: 0.17784 test_confound_acc: 0.551 test_emotion_uar: 0.530 test_confound_uar: 0.562\n",
      "epoch: 6/10\n",
      "train_emotion_loss: 0.96091 train_emotion_acc: 0.573 train_confound_loss: 0.68867 train_confound_acc: 0.546 test_emotion_loss: 0.25046 test_emotion_acc: 0.559 test_confound_loss: 0.17984 test_confound_acc: 0.521 test_emotion_uar: 0.551 test_confound_uar: 0.525\n",
      "epoch: 7/10\n",
      "train_emotion_loss: 0.95306 train_emotion_acc: 0.584 train_confound_loss: 0.68868 train_confound_acc: 0.541 test_emotion_loss: 0.25044 test_emotion_acc: 0.560 test_confound_loss: 0.17997 test_confound_acc: 0.515 test_emotion_uar: 0.549 test_confound_uar: 0.515\n",
      "epoch: 8/10\n",
      "train_emotion_loss: 0.95385 train_emotion_acc: 0.581 train_confound_loss: 0.68926 train_confound_acc: 0.534 test_emotion_loss: 0.25071 test_emotion_acc: 0.558 test_confound_loss: 0.18007 test_confound_acc: 0.515 test_emotion_uar: 0.548 test_confound_uar: 0.514\n",
      "epoch: 9/10\n",
      "train_emotion_loss: 0.94732 train_emotion_acc: 0.586 train_confound_loss: 0.69094 train_confound_acc: 0.525 test_emotion_loss: 0.25047 test_emotion_acc: 0.560 test_confound_loss: 0.18005 test_confound_acc: 0.517 test_emotion_uar: 0.549 test_confound_uar: 0.518\n",
      "epoch: 10/10\n",
      "train_emotion_loss: 0.95026 train_emotion_acc: 0.586 train_confound_loss: 0.68899 train_confound_acc: 0.538 test_emotion_loss: 0.25040 test_emotion_acc: 0.560 test_confound_loss: 0.18005 test_confound_acc: 0.519 test_emotion_uar: 0.548 test_confound_uar: 0.521\n"
     ]
    }
   ],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 2, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "requested-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "epoch: 1/10\n",
      "train_emotion_loss: 1.09400 train_emotion_acc: 0.366 train_confound_loss: 0.69898 train_confound_acc: 0.499 test_emotion_loss: 0.27083 test_emotion_acc: 0.506 test_confound_loss: 0.18330 test_confound_acc: 0.418 test_emotion_uar: 0.335 test_confound_uar: 0.272\n",
      "epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/src/stressed_emotion/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_emotion_loss: 1.03172 train_emotion_acc: 0.498 train_confound_loss: 0.69526 train_confound_acc: 0.528 test_emotion_loss: 0.25574 test_emotion_acc: 0.539 test_confound_loss: 0.17665 test_confound_acc: 0.497 test_emotion_uar: 0.437 test_confound_uar: 0.605\n",
      "epoch: 3/10\n",
      "train_emotion_loss: 0.99116 train_emotion_acc: 0.538 train_confound_loss: 0.68868 train_confound_acc: 0.544 test_emotion_loss: 0.25314 test_emotion_acc: 0.532 test_confound_loss: 0.17365 test_confound_acc: 0.612 test_emotion_uar: 0.445 test_confound_uar: 0.657\n",
      "epoch: 4/10\n",
      "train_emotion_loss: 0.96983 train_emotion_acc: 0.557 train_confound_loss: 0.68726 train_confound_acc: 0.559 test_emotion_loss: 0.25108 test_emotion_acc: 0.537 test_confound_loss: 0.17413 test_confound_acc: 0.585 test_emotion_uar: 0.483 test_confound_uar: 0.623\n",
      "epoch: 5/10\n",
      "train_emotion_loss: 0.95895 train_emotion_acc: 0.569 train_confound_loss: 0.68482 train_confound_acc: 0.566 test_emotion_loss: 0.25197 test_emotion_acc: 0.536 test_confound_loss: 0.17561 test_confound_acc: 0.524 test_emotion_uar: 0.501 test_confound_uar: 0.564\n",
      "epoch: 6/10\n",
      "train_emotion_loss: 0.95184 train_emotion_acc: 0.587 train_confound_loss: 0.68631 train_confound_acc: 0.547 test_emotion_loss: 0.25090 test_emotion_acc: 0.541 test_confound_loss: 0.17624 test_confound_acc: 0.541 test_emotion_uar: 0.503 test_confound_uar: 0.557\n",
      "epoch: 7/10\n",
      "train_emotion_loss: 0.93909 train_emotion_acc: 0.601 train_confound_loss: 0.68663 train_confound_acc: 0.557 test_emotion_loss: 0.25098 test_emotion_acc: 0.538 test_confound_loss: 0.17640 test_confound_acc: 0.537 test_emotion_uar: 0.502 test_confound_uar: 0.554\n",
      "epoch: 8/10\n",
      "train_emotion_loss: 0.94064 train_emotion_acc: 0.596 train_confound_loss: 0.68802 train_confound_acc: 0.543 test_emotion_loss: 0.25106 test_emotion_acc: 0.538 test_confound_loss: 0.17646 test_confound_acc: 0.537 test_emotion_uar: 0.503 test_confound_uar: 0.553\n",
      "epoch: 9/10\n",
      "train_emotion_loss: 0.93710 train_emotion_acc: 0.601 train_confound_loss: 0.68574 train_confound_acc: 0.557 test_emotion_loss: 0.25110 test_emotion_acc: 0.536 test_confound_loss: 0.17648 test_confound_acc: 0.535 test_emotion_uar: 0.502 test_confound_uar: 0.551\n",
      "epoch: 10/10\n",
      "train_emotion_loss: 0.93905 train_emotion_acc: 0.600 train_confound_loss: 0.68655 train_confound_acc: 0.550 test_emotion_loss: 0.25107 test_emotion_acc: 0.537 test_confound_loss: 0.17648 test_confound_acc: 0.536 test_emotion_uar: 0.503 test_confound_uar: 0.552\n"
     ]
    }
   ],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 3, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "virgin-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "epoch: 1/10\n",
      "train_emotion_loss: 1.09515 train_emotion_acc: 0.356 train_confound_loss: 0.69853 train_confound_acc: 0.464 test_emotion_loss: 0.28314 test_emotion_acc: 0.505 test_confound_loss: 0.19179 test_confound_acc: 0.232 test_emotion_uar: 0.411 test_confound_uar: 0.232\n",
      "epoch: 2/10\n",
      "train_emotion_loss: 1.03523 train_emotion_acc: 0.497 train_confound_loss: 0.70149 train_confound_acc: 0.435 test_emotion_loss: 0.26472 test_emotion_acc: 0.538 test_confound_loss: 0.18564 test_confound_acc: 0.454 test_emotion_uar: 0.421 test_confound_uar: 0.449\n",
      "epoch: 3/10\n",
      "train_emotion_loss: 1.00367 train_emotion_acc: 0.516 train_confound_loss: 0.68288 train_confound_acc: 0.565 test_emotion_loss: 0.26100 test_emotion_acc: 0.544 test_confound_loss: 0.18001 test_confound_acc: 0.527 test_emotion_uar: 0.466 test_confound_uar: 0.597\n",
      "epoch: 4/10\n",
      "train_emotion_loss: 0.98333 train_emotion_acc: 0.543 train_confound_loss: 0.68287 train_confound_acc: 0.557 test_emotion_loss: 0.26050 test_emotion_acc: 0.535 test_confound_loss: 0.18216 test_confound_acc: 0.509 test_emotion_uar: 0.481 test_confound_uar: 0.539\n",
      "epoch: 5/10\n",
      "train_emotion_loss: 0.97809 train_emotion_acc: 0.547 train_confound_loss: 0.68765 train_confound_acc: 0.544 test_emotion_loss: 0.26158 test_emotion_acc: 0.524 test_confound_loss: 0.18446 test_confound_acc: 0.479 test_emotion_uar: 0.471 test_confound_uar: 0.489\n",
      "epoch: 6/10\n",
      "train_emotion_loss: 0.97093 train_emotion_acc: 0.558 train_confound_loss: 0.68870 train_confound_acc: 0.540 test_emotion_loss: 0.25974 test_emotion_acc: 0.535 test_confound_loss: 0.18398 test_confound_acc: 0.484 test_emotion_uar: 0.485 test_confound_uar: 0.497\n",
      "epoch: 7/10\n",
      "train_emotion_loss: 0.96299 train_emotion_acc: 0.573 train_confound_loss: 0.68756 train_confound_acc: 0.547 test_emotion_loss: 0.25992 test_emotion_acc: 0.537 test_confound_loss: 0.18396 test_confound_acc: 0.485 test_emotion_uar: 0.490 test_confound_uar: 0.498\n",
      "epoch: 8/10\n",
      "train_emotion_loss: 0.96158 train_emotion_acc: 0.570 train_confound_loss: 0.68681 train_confound_acc: 0.550 test_emotion_loss: 0.25996 test_emotion_acc: 0.536 test_confound_loss: 0.18397 test_confound_acc: 0.484 test_emotion_uar: 0.488 test_confound_uar: 0.497\n",
      "epoch: 9/10\n",
      "train_emotion_loss: 0.96780 train_emotion_acc: 0.568 train_confound_loss: 0.68775 train_confound_acc: 0.547 test_emotion_loss: 0.25999 test_emotion_acc: 0.534 test_confound_loss: 0.18397 test_confound_acc: 0.485 test_emotion_uar: 0.485 test_confound_uar: 0.499\n",
      "epoch: 10/10\n",
      "train_emotion_loss: 0.96902 train_emotion_acc: 0.568 train_confound_loss: 0.68840 train_confound_acc: 0.537 test_emotion_loss: 0.25998 test_emotion_acc: 0.534 test_confound_loss: 0.18397 test_confound_acc: 0.485 test_emotion_uar: 0.485 test_confound_uar: 0.499\n"
     ]
    }
   ],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 4, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "piano-builder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAANRUlEQVR4nO3dcYjf913H8edrl0XFDfdHThhJ2AXNBsecnZ5ZoaCjtnC1kgirI5GNFTqDsGClQ01RAsZ/3AbVf/LH4lYdas1qFTndSSiuIoqtuW61eonRM1ZzQei1q04Rm517+8f9On9efsnvm+R39/M+93zAwe/7/X643/tLyZMv3999f01VIUna+t407gEkSaNh0CWpEQZdkhph0CWpEQZdkhqxY1xvvGvXrpqamhrX20vSlvT888+/UlWTg46NLehTU1MsLCyM6+0laUtK8k/XO+YtF0lqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqxNieFL0dU8e/MO4RRualX7p/3CNIaoRX6JLUCIMuSY3oFPQks0kuJllKcvw6az6Y5HySxSRPjHZMSdIwQ++hJ5kATgH3AsvAuSRzVXW+b81+4FHgrqp6Lcm3b9TAkqTBulyhHwCWqupSVV0FzgCH1q35ceBUVb0GUFUvj3ZMSdIwXYK+G7jct73c29fvncA7k/x5kmeTzA76RUmOJllIsrCysnJrE0uSBhrVh6I7gP3A+4EjwK8medv6RVV1uqpmqmpmcnLg/3BDknSLugT9CrC3b3tPb1+/ZWCuqr5WVf8I/B1rgZckbZIuDxadA/Yn2cdayA8DP7Zuze+zdmX+a0l2sXYL5tII51SfVh6s8qEqabSGXqFX1SpwDDgLXACerKrFJCeTHOwtOwu8muQ88Azw01X16kYNLUm6VqdH/6tqHphft+9E3+sCHun9SJLGwCdFJakRBl2SGrElv21R21crHwiDHwpr9LxCl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoSP/kvaEvzah+EMurSFtBI1v8dmY3jLRZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRGdgp5kNsnFJEtJjg84/mCSlSQv9H4+OvpRJUk3MvS7XJJMAKeAe4Fl4FySuao6v27p56vq2AbMKEnqoMsV+gFgqaouVdVV4AxwaGPHkiTdrC5B3w1c7tte7u1b7wNJXkzyVJK9g35RkqNJFpIsrKys3MK4kqTrGdWHon8ATFXVe4Cngc8NWlRVp6tqpqpmJicnR/TWkiToFvQrQP8V957evm+oqler6vXe5meA7x3NeJKkrroE/RywP8m+JDuBw8Bc/4Ikb+/bPAhcGN2IkqQuhv6VS1WtJjkGnAUmgMerajHJSWChquaAn0xyEFgFvgI8uIEzS5IG6PS/oKuqeWB+3b4Tfa8fBR4d7WiSpJvhk6KS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmN6BT0JLNJLiZZSnL8Bus+kKSSzIxuRElSF0ODnmQCOAXcB0wDR5JMD1j3VuBh4LlRDylJGq7LFfoBYKmqLlXVVeAMcGjAul8EPgH81wjnkyR11CXou4HLfdvLvX3fkOR7gL1V9YUb/aIkR5MsJFlYWVm56WElSdd32x+KJnkT8Bjw8WFrq+p0Vc1U1czk5OTtvrUkqU+XoF8B9vZt7+nte8NbgXcDf5LkJeBOYM4PRiVpc3UJ+jlgf5J9SXYCh4G5Nw5W1b9V1a6qmqqqKeBZ4GBVLWzIxJKkgYYGvapWgWPAWeAC8GRVLSY5meTgRg8oSepmR5dFVTUPzK/bd+I6a99/+2NJkm6WT4pKUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1olPQk8wmuZhkKcnxAcd/IslfJ3khyZ8lmR79qJKkGxka9CQTwCngPmAaODIg2E9U1XdV1R3AJ4HHRj2oJOnGulyhHwCWqupSVV0FzgCH+hdU1Vf7Nr8VqNGNKEnqYkeHNbuBy33by8D71i9K8jHgEWAncPdIppMkdTayD0Wr6lRVfQfws8DPD1qT5GiShSQLKysro3prSRLdgn4F2Nu3vae373rOAD8y6EBVna6qmaqamZyc7DykJGm4LkE/B+xPsi/JTuAwMNe/IMn+vs37gb8f3YiSpC6G3kOvqtUkx4CzwATweFUtJjkJLFTVHHAsyT3A14DXgI9s5NCSpGt1+VCUqpoH5tftO9H3+uERzyVJukk+KSpJjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjegU9CSzSS4mWUpyfMDxR5KcT/Jikj9O8o7RjypJupGhQU8yAZwC7gOmgSNJptct+zIwU1XvAZ4CPjnqQSVJN9blCv0AsFRVl6rqKnAGONS/oKqeqar/7G0+C+wZ7ZiSpGG6BH03cLlve7m373oeAv5o0IEkR5MsJFlYWVnpPqUkaaiRfiia5EPADPCpQcer6nRVzVTVzOTk5CjfWpK2vR0d1lwB9vZt7+nt+z+S3AP8HPADVfX6aMaTJHXV5Qr9HLA/yb4kO4HDwFz/giTvBT4NHKyql0c/piRpmKFBr6pV4BhwFrgAPFlVi0lOJjnYW/Yp4C3A7yR5IcncdX6dJGmDdLnlQlXNA/Pr9p3oe33PiOeSJN0knxSVpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqRKegJ5lNcjHJUpLjA45/f5IvJVlN8sDox5QkDTM06EkmgFPAfcA0cCTJ9Lpl/ww8CDwx6gElSd3s6LDmALBUVZcAkpwBDgHn31hQVS/1jn19A2aUJHXQ5ZbLbuBy3/Zyb99NS3I0yUKShZWVlVv5FZKk69jUD0Wr6nRVzVTVzOTk5Ga+tSQ1r0vQrwB7+7b39PZJkv4f6RL0c8D+JPuS7AQOA3MbO5Yk6WYNDXpVrQLHgLPABeDJqlpMcjLJQYAk35dkGfhR4NNJFjdyaEnStbr8lQtVNQ/Mr9t3ou/1OdZuxUiSxsQnRSWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEZ2CnmQ2ycUkS0mODzj+TUk+3zv+XJKpkU8qSbqhoUFPMgGcAu4DpoEjSabXLXsIeK2qvhP4ZeATox5UknRjXa7QDwBLVXWpqq4CZ4BD69YcAj7Xe/0U8INJMroxJUnDpKpuvCB5AJitqo/2tj8MvK+qjvWt+ZvemuXe9j/01ryy7ncdBY72Nt8FXBzViWyQXcArQ1e1yXPfvrbz+W+Fc39HVU0OOrBjM6eoqtPA6c18z9uRZKGqZsY9xzh47tvz3GF7n/9WP/cut1yuAHv7tvf09g1ck2QH8G3Aq6MYUJLUTZegnwP2J9mXZCdwGJhbt2YO+Ejv9QPAF2vYvRxJ0kgNveVSVatJjgFngQng8apaTHISWKiqOeCzwG8kWQK+wlr0W7Blbg9tAM99+9rO57+lz33oh6KSpK3BJ0UlqREGXZIaYdAHGPZVBy1L8niSl3vPFmwrSfYmeSbJ+SSLSR4e90ybJck3J/nLJH/VO/dfGPdM45BkIsmXk/zhuGe5FQZ9nY5fddCyXwdmxz3EmKwCH6+qaeBO4GPb6L/968DdVfXdwB3AbJI7xzvSWDwMXBj3ELfKoF+ry1cdNKuq/pS1v1TadqrqX6rqS73X/87aP+zd451qc9Sa/+htvrn3s63+YiLJHuB+4DPjnuVWGfRr7QYu920vs03+Uet/9b4x9L3Ac2MeZdP0bje8ALwMPF1V2+bce34F+Bng62Oe45YZdGmdJG8Bfhf4qar66rjn2SxV9d9VdQdrT4MfSPLuMY+0aZL8MPByVT0/7lluh0G/VpevOlCjkryZtZj/VlX93rjnGYeq+lfgGbbXZyl3AQeTvMTabda7k/zmeEe6eQb9Wl2+6kAN6n3l82eBC1X12Ljn2UxJJpO8rff6W4B7gb8d61CbqKoerao9VTXF2r/5L1bVh8Y81k0z6OtU1SrwxlcdXACerKrF8U61eZL8NvAXwLuSLCd5aNwzbaK7gA+zdnX2Qu/nh8Y91CZ5O/BMkhdZu6h5uqq25J/ubWc++i9JjfAKXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIa8T9fq0jKHG/09AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(5),acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "figured-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(5),uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "designed-potter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6195711929631665, 0.5919381557150746, 0.576310861423221, 0.54113171659534, 0.543778801843318]\n",
      "[0.5797473004493539, 0.5560675776078008, 0.6660561453766521, 0.5032713284393016, 0.489619002034886]\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ordered-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "appropriate-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619571</td>\n",
       "      <td>0.579747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.591938</td>\n",
       "      <td>0.556068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.576311</td>\n",
       "      <td>0.666056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.541132</td>\n",
       "      <td>0.503271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.489619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.619571  0.579747\n",
       "1  0.591938  0.556068\n",
       "2  0.576311  0.666056\n",
       "3  0.541132  0.503271\n",
       "4  0.543779  0.489619"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([acc,uar]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "czech-peripheral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.574546145708024"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "continuous-exemption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5589522707815988"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "b045124bcdd1c40b84b667cdfcc8f45f39bd89c671aa4fba75a85560739fc3dc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}